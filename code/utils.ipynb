{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing and post classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter as C\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"../data/data/all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all files in models ie logs\n",
    "#[os.path.join(top, file) for top, dirs, files in os.walk(\"./hate-speech-detection/models\") for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all images\n",
    "#os.listdir(\"../data/data/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## displaying all rows of df\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting test data\n",
    "#test_data = pd.read_json(\"../data/data/test.jsonl\", lines=True)\n",
    "#test = test_data.sort_values(by=[\"img\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_accuracys(path):\n",
    "    # opening .accuracys files and getting the file names of the images with the lowest and highest squared error\n",
    "    with open(path) as f:\n",
    "        file = f.read()\n",
    "        file = file.split(\"\\n\")\n",
    "    file = [x.split(\"\\t\")[0].split(\"/\")[5].split(\".\")[0] for x in file if x.startswith(\"..\")]\n",
    "    return file[:20], file[20:] # lowest squared error, highest squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_0_11, bott100_0_11 = open_accuracys(\"./hate-speech-detection/results/models/clf100.0.11.pt.accuracys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_0_b11, bott100_0_b11 = open_accuracys(\"./hate-speech-detection/results/models/clf100.0.b11.pt.accuracys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3b01, bott3b01 = open_accuracys(\"./hate-speech-detection/results/accuracys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bott = [top100_0_11, bott100_0_11, top100_0_b11, bott100_0_b11, top3b01, bott3b01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for x in top100_0_b11:\n",
    "    im = Image.open(\"../data/data/img/\" + str(x) + \".png\")\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(lst):\n",
    "    return [subsublist for sublist in lst for subsublist in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_counts(lst):\n",
    "    \n",
    "    x = all_data[all_data[\"id\"].isin(lst)]\n",
    "    x = x.text.to_list()\n",
    "    \n",
    "    # getting a list of bigrams for each sentence (including punctuation unfortunately) by splitting on everything that's not a word\n",
    "    # maybe rm punctuation instead?\n",
    "    bigrams = [{(w.lower(), re.split(r\"(\\W+)\", sent)[i+1].lower()) for i, w in enumerate(sent.split(\" \")) if i != (len(sent.split(\" \"))-1)} for sent in x ]\n",
    "    bigrams = flatten_list(bigrams)\n",
    "    \n",
    "    words = [{w.lower() for w in set(re.split(r\"(\\W+)\", sent))} for sent in x]\n",
    "    words = flatten_list(words)\n",
    "    \n",
    "    count_words = C(words)\n",
    "    count_bigrams = C(bigrams)\n",
    "    \n",
    "    return dict(sorted(count_words.items(), key=lambda item: item[1], reverse=True)), dict(sorted(count_bigrams.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_0_11c, bott100_0_11c, top100_0_b11c, bott100_0_b11c, top3b01c, bott3b01c = [get_text_counts(l) for l in top_bott]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3b01c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(w_list, img_list):\n",
    "    x = all_data[all_data[\"id\"].isin(img_list)].reset_index(drop=True)\n",
    "    w_id = {}\n",
    "    for row in x.iterrows():\n",
    "        split = re.split(r\"(\\W+)\", row[1].text)\n",
    "        img = row[1].id\n",
    "        for w in split:\n",
    "            if w in w_list:\n",
    "                if w not in w_id.keys():\n",
    "                    w_id[w] = set()\n",
    "                    w_id[w].add(img)\n",
    "                else:\n",
    "                    w_id[w].add(img)\n",
    "    return w_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_words([\"muslim\", \"muslims\", \"islam\", \"religion\"], top100_0_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "top_accs_tok[0].intersection(top_accs_tok[1], top_accs_tok[2], top_accs_tok[3], top_accs_tok[4], top_accs_tok[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.intersection(*[set(x) for x in top_accs_tok])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_accs_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origin = \"../data/data/\"\n",
    "#destination = \"../data/data/test/\"\n",
    "#os.mkdir(\"../data/data/test/\")\n",
    "#for img in test_data.img.tolist():\n",
    "#    os.rename((origin+img), (destination+img.lstrip(\"img/\")))\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_json(\"../data/data/dev.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json(\"../data/data/train.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([dev_data, train_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len label 0: 5700 = 0.63\n",
    "# len label 1: 3300 = 0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data[all_data[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['id'] = list(map(lambda x: str(x).zfill(5), all_data['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data['set'] = all_data.shape[0] * ['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsize = int(((15/100))*all_data.shape[0])\n",
    "valsize = testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testsize * ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = valsize * ['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.sample(frac=1).reset_index(drop=True) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[:(testsize-1), 'set'] = test # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[testsize:(testsize+valsize-1), 'set'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/data/all_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data/all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_val = df[(df['set'] == 'val') & (df['label'] == 0)].reset_index(drop=True)\n",
    "off_val = df[(df['set'] == 'val') & (df['label'] == 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_train = df[(df['set'] == 'train') & (df['label'] == 0)].reset_index(drop=True)\n",
    "off_train = df[(df['set'] == 'train') & (df['label'] == 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_train.shape[0]/(not_train.shape[0] + off_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_test = df[(df['set'] == 'test') & (df['label'] == 0)].reset_index(drop=True)\n",
    "off_test = df[(df['set'] == 'test') & (df['label'] == 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([not_val, off_val, not_test, off_test, not_train, off_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "856/(856+494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_train_size = not_train[:2304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3996+2304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3996/(3996+2304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if test:\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_txt(df, filename):\n",
    "    file = \"../data/data/\" + filename\n",
    "    with open(file, 'w') as f:\n",
    "        for img in df.img.to_list():\n",
    "            f.write(img+\"\\n\")\n",
    "    print(\"Done!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_txt(not_test, \"goodMemesList.txt.test\")\n",
    "write_txt(off_test, \"hateMemesList.txt.test\")\n",
    "write_txt(not_train, \"goodMemesList.txt.train\")\n",
    "write_txt(off_train, \"hateMemesList.txt.train\")\n",
    "write_txt(not_val, \"goodMemesList.txt.val\")\n",
    "write_txt(off_val, \"hateMemesList.txt.val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = df.copy()[df[\"label\"] == 1]\n",
    "label_0 = df.copy()[df[\"label\"] == 0].sample(n=3300)\n",
    "balanced = pd.concat([label_1, label_0], ignore_index=True).to_csv(\"../data/data/balanced_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv(\"../data/data/balanced_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_not_val = balanced_df[(balanced_df['set'] == 'val') & (balanced_df['label'] == 0)].reset_index(drop=True)\n",
    "bal_off_val = balanced_df[(balanced_df['set'] == 'val') & (balanced_df['label'] == 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_not_train = balanced_df[(balanced_df['set'] == 'train') & (balanced_df['label'] == 0)].reset_index(drop=True)\n",
    "bal_off_train = balanced_df[(balanced_df['set'] == 'train') & (balanced_df['label'] == 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_not_test = balanced_df[(balanced_df['set'] == 'test') & (balanced_df['label'] == 0)].reset_index(drop=True)\n",
    "bal_off_test = balanced_df[(balanced_df['set'] == 'test') & (balanced_df['label'] == 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([bal_not_test, bal_off_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(bal_not_test, \"bal.goodMemesList.txt.test\")\n",
    "write_txt(bal_off_test, \"bal.hateMemesList.txt.test\")\n",
    "write_txt(bal_not_train, \"bal.goodMemesList.txt.train\")\n",
    "write_txt(bal_off_train, \"bal.hateMemesList.txt.train\")\n",
    "write_txt(bal_not_val, \"bal.goodMemesList.txt.val\")\n",
    "write_txt(bal_off_val, \"bal.hateMemesList.txt.val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_caption_to_file(df, basedir):\n",
    "    for img, text in zip(df.loc[:, \"img\"].to_list(), df.loc[:, \"text\"].to_list()):\n",
    "        filename = basedir + img + \".ocr\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            #print(filename)\n",
    "            \n",
    "            f.write(text)\n",
    "        #break\n",
    "    print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_caption_to_file(off_test, \"/home/gushansad@GU.GU.SE/lt2318-ai/aics-project/data/data/\")\n",
    "write_caption_to_file(not_test, \"/home/gushansad@GU.GU.SE/lt2318-ai/aics-project/data/data/\")\n",
    "write_caption_to_file(not_train, \"/home/gushansad@GU.GU.SE/lt2318-ai/aics-project/data/data/\")\n",
    "write_caption_to_file(off_train, \"/home/gushansad@GU.GU.SE/lt2318-ai/aics-project/data/data/\")\n",
    "write_caption_to_file(not_val, \"/home/gushansad@GU.GU.SE/lt2318-ai/aics-project/data/data/\")\n",
    "write_caption_to_file(off_val, \"/home/gushansad@GU.GU.SE/lt2318-ai/aics-project/data/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir = os.listdir(\"../data/data/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in imgdir if x.endswith(\".ocr\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = not offensive, 1 = offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(open(\"../data/data/bal.hateMemesList.txt.val\"))\n",
    "list(open(\"../data/data/bal.hateMemesList.txt.val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "9000*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../../data/img/\"\n",
    "for img in dev.img.to_list():\n",
    "    old_path = base + img\n",
    "    new_path = base + \"dev/\" + img\n",
    "    os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../../data/img/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_paths = list(open(os.getcwd() + \"/\" + \"garbage.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
